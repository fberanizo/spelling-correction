{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BEA2019_T5_FineTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5acfb1caa66d414c862e26ab1174c6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_568f48cf9c26454b8aa214770470aefb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_616a530858134a8088283f57f0da41f6",
              "IPY_MODEL_cbebb77c636c4979be37c80958b9ff6a"
            ]
          }
        },
        "568f48cf9c26454b8aa214770470aefb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "616a530858134a8088283f57f0da41f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a44a9929a9949b2835c64eff46ba0d9",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_681dbde509e54f41a188c2a229edfa43"
          }
        },
        "cbebb77c636c4979be37c80958b9ff6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f857124a106438ba038ce5189f7da8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:31&lt;00:00, 15.00s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9c0754e2378451ebbe89886fda4063f"
          }
        },
        "9a44a9929a9949b2835c64eff46ba0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "681dbde509e54f41a188c2a229edfa43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f857124a106438ba038ce5189f7da8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9c0754e2378451ebbe89886fda4063f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0506e5bf96e24876bc683efbe28b9c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dbed467f06cb4e0b85f8c40e2df2bc01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bcb9864799d435d9f572e8c35666e52",
              "IPY_MODEL_0cc544a887854029944cf30d86bc5187"
            ]
          }
        },
        "dbed467f06cb4e0b85f8c40e2df2bc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "7bcb9864799d435d9f572e8c35666e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffd49a0c613d45658b3034b48b9375ca",
            "_dom_classes": [],
            "description": "Epoch 5:   6%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 650,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 41,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2feab53ddfa40d6a14ef1d329de03c6"
          }
        },
        "0cc544a887854029944cf30d86bc5187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b977668d33c64dc39b7156729d576570",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41/650 [00:17&lt;04:15,  2.39it/s, loss=0.006, v_num=3, cpu=53.6%, mem=29.4%, gpu=35%, gpu_mem=16%, avg_precision=0.311, avg_recall=0.167, avg_f_score=0.26]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b223f11c77b4501a45343fa5d327f54"
          }
        },
        "ffd49a0c613d45658b3034b48b9375ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2feab53ddfa40d6a14ef1d329de03c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b977668d33c64dc39b7156729d576570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b223f11c77b4501a45343fa5d327f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc297e705a0945468a584dfb510d5d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_492ea405200a447c9dfc31519636a67f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58b622a7fb294b908d3b73f6a9590565",
              "IPY_MODEL_3e1bbc45f55d4663988e689dfee128b6"
            ]
          }
        },
        "492ea405200a447c9dfc31519636a67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "58b622a7fb294b908d3b73f6a9590565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5c3494bd7bb46efad13d8e64bf8fcff",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_105243e6c3a24dc494c1abfed131f57a"
          }
        },
        "3e1bbc45f55d4663988e689dfee128b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e684f676b2e14ed4a24c592f217b0bb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [2:36:04&lt;00:00, 60.94s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30a0f593141948359e011df6e69f2db2"
          }
        },
        "f5c3494bd7bb46efad13d8e64bf8fcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "105243e6c3a24dc494c1abfed131f57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e684f676b2e14ed4a24c592f217b0bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30a0f593141948359e011df6e69f2db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "859ecf02643c4044b2b663fad56bc924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fabbfc8416e44466b80ab4e74fa2d868",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14e111f5f0e44b739bfe0b0bab88358f",
              "IPY_MODEL_b059f53bcb634d22914ad3b6695969da"
            ]
          }
        },
        "fabbfc8416e44466b80ab4e74fa2d868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "14e111f5f0e44b739bfe0b0bab88358f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1299261b55c47b995696f2599dbee36",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_997152ef72124eb6948ca7214e6de28d"
          }
        },
        "b059f53bcb634d22914ad3b6695969da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9256bd0c1db941279fd0514d23b7a605",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [1:37:44&lt;00:00, 48.77s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30f23eb47abe41ae8621a3bb6b018079"
          }
        },
        "b1299261b55c47b995696f2599dbee36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "997152ef72124eb6948ca7214e6de28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9256bd0c1db941279fd0514d23b7a605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30f23eb47abe41ae8621a3bb6b018079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e418c84e0f464e1b97c1cbbed06c1258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68e61f84ada94b69acd4bb264c43a9b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_455768c76f57408c9db1d60cdae81c74",
              "IPY_MODEL_60e9f41967864fe491d22716a600d025"
            ]
          }
        },
        "68e61f84ada94b69acd4bb264c43a9b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "455768c76f57408c9db1d60cdae81c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_815b5457c39b4ed6a304aa8d28c7d46e",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19789ffab1d540f6a872a1c6d010de2f"
          }
        },
        "60e9f41967864fe491d22716a600d025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01bf7dc988a847aa94dfd287681ec843",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [49:48&lt;00:00, 19.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9d6bdd269db4de9a38030b8f6cb8e7d"
          }
        },
        "815b5457c39b4ed6a304aa8d28c7d46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19789ffab1d540f6a872a1c6d010de2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01bf7dc988a847aa94dfd287681ec843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9d6bdd269db4de9a38030b8f6cb8e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7902c80f9dc34eb883501134b2cd3230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d618afbfc1fa46d8a51e705765d9e027",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_02ff6e69e97f46a2ac25222322356081",
              "IPY_MODEL_510898434dcf401480d0b6b7144ffd9c"
            ]
          }
        },
        "d618afbfc1fa46d8a51e705765d9e027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "02ff6e69e97f46a2ac25222322356081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb68ca892f7e43ccb672f35bc10f52ce",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc5988bb8d3c4b4785b42afdae19e56f"
          }
        },
        "510898434dcf401480d0b6b7144ffd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7c58014d6cd46a5922888602e9364fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [46:58&lt;00:00, 28.75s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_967d517f70b8402abe1b95584521a80d"
          }
        },
        "fb68ca892f7e43ccb672f35bc10f52ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc5988bb8d3c4b4785b42afdae19e56f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7c58014d6cd46a5922888602e9364fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "967d517f70b8402abe1b95584521a80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fberanizo/spelling-correction/blob/master/BEA2019_T5_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up4u8rMkQSG",
        "colab_type": "text"
      },
      "source": [
        "# BEA 2019 Shared Task: Grammatical Error Correction: Modelo T5\n",
        "\n",
        "**Nome: Fabio Beranizo Lopes**<br>\n",
        "**Nome: Luiz Pita Almeida**\n",
        "\n",
        "Usaremos o modelo T5 pré-treinado e o dataset W&I+LOCNESS do [Building Educational Applications 2019 Shared Task: Grammatical Error Correction](https://www.cl.cam.ac.uk/research/nl/bea2019st). <br>\n",
        "Truncamos para strings de tamanho 100 para deixar os testes mais rápidos.\n",
        "\n",
        "Métrica de avaliação: F0.5-score <br>\n",
        "https://www.cl.cam.ac.uk/research/nl/bea2019st/#eval\n",
        "\n",
        "O método de correção aplicado foi realizar fine-tuning em no modelo T5 para a tarefa de correção.\n",
        "\n",
        "Passos:\n",
        "\n",
        "1. Geram-se tuplas: `(original, corrected)`\n",
        "2. Aplica-se modelo T5 para prever top-10 palavras.<br>\n",
        "   Caso a palavra original esteja no Top 10 do modelo, é classificada como correta.<br>\n",
        "   Senão, a palavra é classificada como incorreta.\n",
        "\n",
        "**Obs: os notebooks contém excertos de códigos dos colegas de turma.**<br>\n",
        "**Obrigado Diedre, Gabriela, Leard, Lucas e Israel.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpELBvNmku5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b4d7896-a82a-41d7-8118-ddbe792befac"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# don't even start if it's not a P100 GPU\n",
        "# if torch.cuda.get_device_name(0) != \"Tesla P100-PCIE-16GB\":\n",
        "#     import os\n",
        "#     os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgW-boJLU0wU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Configurações gerais\n",
        "experiment_name = \"fine-tuning\" #@param {type:\"string\"}\n",
        "model_name = \"t5-small\"  #@param [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3B\", \"t5-11B\"] {type:\"string\"}\n",
        "max_epochs = 10 #@param {type:\"integer\"}\n",
        "batch_size =  2 #@param {type:\"integer\"}\n",
        "accumulate_grad_batches =   25#@param {type:\"integer\"}\n",
        "sequence_length = 1000  #@param {type:\"integer\"}\n",
        "learning_rate = 5e-3  #@param {type:\"number\"}\n",
        "decode_mode = \"topk\"  #@param [\"greedy\", \"nucleus\", \"topk\", \"beam\"] {type:\"string\"}\n",
        "k = 10  #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U0dTSB-mnGN",
        "colab_type": "text"
      },
      "source": [
        "## Instala dependências\n",
        "\n",
        "- PyTorch Lightning\n",
        "- Hugginface Transformers\n",
        "- ERRANT (ERRor ANnotation Toolkit)\n",
        "- pyxDamerauLevenshtein"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOXZxjWRkLMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import pytorch_lightning\n",
        "    import transformers\n",
        "except ImportError as e:\n",
        "    # can't import modules, then install\n",
        "    !pip install --quiet pytorch-lightning\n",
        "    !pip install --quiet transformers\n",
        "    !pip install --quiet errant==2.0.0\n",
        "    !pip install pyxDamerauLevenshtein\n",
        "    !python -m spacy download en\n",
        "    # kill kernel (necessary for tqdm)\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob7qL6kUVjbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importar todos os pacotes de uma só vez para evitar duplicados ao longo do notebook.\n",
        "import datetime\n",
        "import errant\n",
        "import gzip\n",
        "import json\n",
        "import numpy as np\n",
        "import nvidia_smi\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import psutil\n",
        "import pytorch_lightning as pl\n",
        "import random\n",
        "import spacy\n",
        "import sys\n",
        "import tarfile\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from argparse import Namespace\n",
        "from google.colab import drive\n",
        "from itertools import cycle\n",
        "\n",
        "from pyxdameraulevenshtein import damerau_levenshtein_distance, \\\n",
        "    normalized_damerau_levenshtein_distance\n",
        "from pyxdameraulevenshtein import damerau_levenshtein_distance_ndarray, \\\n",
        "    normalized_damerau_levenshtein_distance_ndarray\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "from transformers import T5ForConditionalGeneration\n",
        "from transformers import T5Tokenizer\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "\n",
        "# Leard decoding solution\n",
        "import html\n",
        "import unicodedata\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "annotator = errant.load(\"en\", nlp)\n",
        "\n",
        "nvidia_smi.nvmlInit()\n",
        "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
        "\n",
        "def hardware_stats():\n",
        "    \"\"\"\n",
        "    Returns a dict containing some hardware related stats\n",
        "    \"\"\"\n",
        "    res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
        "    return {\"cpu\": f\"{str(psutil.cpu_percent())}%\",\n",
        "            \"mem\": f\"{str(psutil.virtual_memory().percent)}%\",\n",
        "            \"gpu\": f\"{str(res.gpu)}%\",\n",
        "            \"gpu_mem\": f\"{str(res.memory)}%\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8H4Rfwm2gE",
        "colab_type": "text"
      },
      "source": [
        "## Define random seeds\n",
        "\n",
        "Importante: Fix seeds so we can replicate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJlZDb1VY29r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "torch.random.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETfkvMGl4JA1",
        "colab_type": "text"
      },
      "source": [
        "## Mapeia Google Drive\n",
        "\n",
        "Iremos salvar os checkpoints (pesos do modelo) no google drive, para que possamos continuar o treino de onde paramos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hvGjweSKfbA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0ad6a7d-3663-4203-e711-1146d4ba6f84"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "base_path = \"/content/drive/My Drive/PF-Correcao/bea2019st-finetuning\"\n",
        "# base_path = \"/content/bea2019st-finetuning\"\n",
        "os.environ[\"BASE_PATH\"] = base_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMhp7hvN9mS6",
        "colab_type": "text"
      },
      "source": [
        "## ERRANT Scorer\n",
        "\n",
        "Comando para avaliação que compara um arquivo M2 \"hipótese\" contra um arquivo M2 \"referência\".<br>\n",
        "\n",
        "### **Example**\n",
        "**Original**: This are gramamtical sentence .<br>\n",
        "**Corrected**: This is a grammatical sentence .<br>\n",
        "**Output M2**:<br>\n",
        "S This are gramamtical sentence .<br>\n",
        "A 1 2|||R:VERB:SVA|||is|||REQUIRED|||-NONE-|||0<br>\n",
        "A 2 2|||M:DET|||a|||REQUIRED|||-NONE-|||0<br>\n",
        "A 2 3|||R:SPELL|||grammatical|||REQUIRED|||-NONE-|||0<br>\n",
        "A -1 -1|||noop|||-NONE-|||REQUIRED|||-NONE-|||1<br>\n",
        "\n",
        "In M2 format, a line preceded by S denotes an original sentence while a line preceded by A indicates an edit annotation. Each edit line consists of the start and end token offset of the edit, the error type, and the tokenized correction string. The next two fields are included for historical reasons (see the CoNLL-2014 shared task) while the last field is the annotator id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWPWngE89ss_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6ff89a9-8608-4349-b9f0-2a407459aa8c"
      },
      "source": [
        "%%writefile orig.txt\n",
        "Eu não cei pra ondi vou .\n",
        "Podi até num dá em nada .\n",
        "Minha vida segui o sol .\n",
        "No horizonti dessa istrada ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting orig.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkdn9fTBS4lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c50e885-f651-4fc0-b0d0-61f277489354"
      },
      "source": [
        "%%writefile ref.txt\n",
        "Eu não sei pra onde vou .\n",
        "Pode até não dar em nada .\n",
        "Minha vida segue o sol .\n",
        "No horizonte dessa estrada ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting ref.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eQ142HVSZu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f1d16e-ca5a-4592-9bfb-ea3001997a02"
      },
      "source": [
        "%%writefile hyp.txt\n",
        "Eu não sei pra ondi vou .\n",
        "Podi até não dar em nada .\n",
        "Minha vida segui u sol .\n",
        "Num horizonte dessa estrada ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting hyp.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6KxhquG8U44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!errant_parallel -orig orig.txt -cor ref.txt -out ref.m2 > /dev/null\n",
        "!errant_parallel -orig orig.txt -cor hyp.txt -out hyp.m2 > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj0qyFWK9pI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "96402991-bfbf-4e42-fa55-b78310719886"
      },
      "source": [
        "import pandas as pd\n",
        "!errant_compare -hyp hyp.m2 -ref ref.m2\n",
        "# x = !errant_compare -hyp hyp.m2 -ref ref.m2\n",
        "# df = pd.DataFrame(data=x[2:4])[0].str.split('\\t', expand=True)\n",
        "# new_header = df.iloc[0] #grab the first row for the header\n",
        "# df = df[1:] #take the data less the header row\n",
        "# df.columns = new_header\n",
        "# df\n",
        "# df[\"F0.5\"][1]\n",
        "# d = df.apply(pd.to_numeric).to_dict('r')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=========== Span-Based Correction ============\n",
            "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
            "5\t2\t3\t0.7143\t0.625\t0.6944\n",
            "==============================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W1V2fdg-RqU",
        "colab_type": "text"
      },
      "source": [
        "## Gerador \n",
        "\n",
        "From:\n",
        "https://github.com/huggingface/transformers/issues/3985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmxoZCZoIq6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "# # Input text\n",
        "# original = 'This are gramamtical sentence .'\n",
        "# correct = 'This is a grammatical sentence .'\n",
        "\n",
        "# text = 'This <extra_id_0> sentence. </s>'\n",
        "\n",
        "# encoded = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
        "# input_ids = encoded['input_ids']\n",
        "\n",
        "# # Generating 20 sequences with maximum length set to 5\n",
        "# outputs = model.generate(input_ids=input_ids, \n",
        "#                           num_beams=200, num_return_sequences=20,\n",
        "#                           max_length=5)\n",
        "\n",
        "# _0_index = text.index('<extra_id_0>')\n",
        "# _result_prefix = text[:_0_index]\n",
        "# _result_suffix = text[_0_index+12:]  # 12 is the length of <extra_id_0>\n",
        "\n",
        "# def _filter(output, end_token='<extra_id_1>'):\n",
        "#     # The first token is <unk> (inidex at 0) and the second token is <extra_id_0> (indexed at 32099)\n",
        "#     _txt = tokenizer.decode(output[2:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
        "#     if end_token in _txt:\n",
        "#         _end_token_index = _txt.index(end_token)\n",
        "#         return _result_prefix + _txt[:_end_token_index] + _result_suffix\n",
        "#     else:\n",
        "#         return _result_prefix + _txt + _result_suffix\n",
        "\n",
        "# results = list(map(_filter, outputs))\n",
        "# results\n",
        "# del tokenizer\n",
        "# del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TgUkD55Dkam2"
      },
      "source": [
        "## Classe Dataset\n",
        "Gerenciamento dos dados, e um pequeno teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R2GaMtgRkaze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "bd95ee43-dc06-4ad4-ee11-9f959c905561"
      },
      "source": [
        "hparams = {\"model_name\": model_name, \"seq_len\": sequence_length, \"batch_size\": batch_size}\n",
        "class BEA2019(Dataset):\n",
        "    \"\"\"\n",
        "    Loads data from preprocessed file and manages them.\n",
        "    \"\"\"\n",
        "    VALID_MODES = [\"train\", \"validation\", \"test\"]\n",
        "    TOKENIZER = T5Tokenizer.from_pretrained(hparams[\"model_name\"],\n",
        "                                            cache_dir=base_path)\n",
        "    def __init__(self, mode: str, seq_len: int):\n",
        "        \"\"\"\n",
        "        mode: One of train, validation or test \n",
        "        seq_len: limit to returned encoded tokens\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert mode in BEA2019.VALID_MODES\n",
        "\n",
        "        self.mode = mode\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        file_name = os.path.join(base_path, f\"{mode}.pkl\")\n",
        "        if not os.path.isfile(file_name):\n",
        "            print(\"Pre-processed files not found, preparing data.\")\n",
        "            self.prepare_data()\n",
        "        \n",
        "        with open(file_name, \"rb\") as preprocessed_file:\n",
        "            self.data = joblib.load(preprocessed_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i: int):\n",
        "        \"\"\"\n",
        "        Unpacks line from data and applies T5 encoding if necessary.\n",
        "\n",
        "        returns: input (corrupted, original), target (corrected)\n",
        "        \"\"\"\n",
        "        input, target = self.data[i]\n",
        "        \n",
        "        input_normalized = unicodedata.normalize(\"NFD\", input).\\\n",
        "            encode(\"latin-1\", \"xmlcharrefreplace\").\\\n",
        "            decode(\"latin-1\")\n",
        "\n",
        "        input_encoded = BEA2019.TOKENIZER.encode_plus(\n",
        "            f\"{input_normalized} {BEA2019.TOKENIZER.eos_token}\",\n",
        "            max_length=self.seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = input_encoded[\"input_ids\"].squeeze()\n",
        "        input_mask = input_encoded[\"attention_mask\"].squeeze()\n",
        "\n",
        "        target_normalized = unicodedata.normalize(\"NFD\", target).\\\n",
        "            encode(\"latin-1\", \"xmlcharrefreplace\").\\\n",
        "            decode(\"latin-1\")\n",
        "\n",
        "        target_encoded = BEA2019.TOKENIZER.encode_plus(\n",
        "            f\"{target_normalized} {BEA2019.TOKENIZER.eos_token}\",\n",
        "            max_length=self.seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors=\"pt\")\n",
        "\n",
        "        target_ids = target_encoded[\"input_ids\"].squeeze()\n",
        "        target_mask = target_encoded[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return input, target, input_ids, input_mask, target_ids, target_mask\n",
        "\n",
        "    def get_dataloader(self, batch_size: int, shuffle: bool):\n",
        "        return DataLoader(self, batch_size=batch_size, shuffle=shuffle, \n",
        "                          num_workers=4)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_text_tuples(path, member):\n",
        "        \"\"\"\n",
        "        Load tuples from original files: text_original, text_corrected.\n",
        "        \"\"\"\n",
        "        text_tuples = []\n",
        "        with tarfile.open(path) as tar:\n",
        "            f = tar.extractfile(member)\n",
        "            for line in f:\n",
        "                data = json.loads(line)\n",
        "                # list of edits, one for each annotators\n",
        "                for annotator_id, edits in data[\"edits\"]:\n",
        "                    # edit: [annotator_id, [[char_start_offset, char_end_offset, correction], ...]]\n",
        "\n",
        "                    text_original = data[\"text\"]\n",
        "                    text_corrected = \"\"\n",
        "                    prev_char_end_offset = 0\n",
        "\n",
        "                    for idx, (char_start_offset, char_end_offset, correction) in enumerate(edits):\n",
        "                        # a slice of unchanged original text \n",
        "                        text_unchanged = text_original[prev_char_end_offset:char_start_offset]\n",
        "\n",
        "                        if correction is None:\n",
        "                            correction = \"\"\n",
        "                        text_corrected = f\"{text_corrected} {text_unchanged}{correction}\"\n",
        "\n",
        "                        prev_char_end_offset = char_end_offset\n",
        "\n",
        "                    text_unchanged = text_original[prev_char_end_offset:]\n",
        "                    text_corrected = f\"{text_corrected} {text_unchanged}\".lstrip()\n",
        "                    text_tuples.append((text_original, text_corrected))\n",
        "\n",
        "        return text_tuples\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_data(train_size=1000, val_size=300, test_size=300):\n",
        "        \"\"\"\n",
        "        Performs everything needed to get the data ready.\n",
        "        Addition of Eos token and encoding is performed in runtime.\n",
        "        \"\"\"\n",
        "        if not os.path.isfile(\"wi+locness_v2.1.bea19.tar.gz\"):    \n",
        "            !wget -nc https://www.cl.cam.ac.uk/research/nl/bea2019st/data/wi+locness_v2.1.bea19.tar.gz -P \"$BASE_PATH\"\n",
        "            # !wget -nc https://www.cl.cam.ac.uk/research/nl/bea2019st/data/ABCN.bea19.dev.orig -P \"$BASE_PATH\"\n",
        "            # !wget -nc https://www.cl.cam.ac.uk/research/nl/bea2019st/data/ABCN.bea19.test.orig -P \"$BASE_PATH\"\n",
        "\n",
        "        data = {}\n",
        "        train_val_data = BEA2019.load_text_tuples(os.path.join(base_path, \"wi+locness_v2.1.bea19.tar.gz\"), \"wi+locness/json/A.train.json\")\n",
        "        test_data = BEA2019.load_text_tuples(os.path.join(base_path, \"wi+locness_v2.1.bea19.tar.gz\"), \"wi+locness/json/A.dev.json\")\n",
        "\n",
        "        random.shuffle(train_val_data)\n",
        "\n",
        "        train_data = train_val_data[:train_size]\n",
        "        val_data = train_val_data[train_size:train_size + val_size]\n",
        "        test_data = test_data[:test_size]\n",
        "\n",
        "        for mode, data in zip(BEA2019.VALID_MODES, [train_data, val_data, test_data]):\n",
        "            file_name = os.path.join(base_path, f\"{mode}.pkl\")\n",
        "            with open(file_name, \"wb\") as pkl_file:\n",
        "                joblib.dump(data, pkl_file)\n",
        "            print(f\"Pre-processed data saved as {file_name}.\")\n",
        "\n",
        "\n",
        "datasets = {m: BEA2019(mode=m, seq_len=hparams[\"seq_len\"]) for m in BEA2019.VALID_MODES}\n",
        "\n",
        "# Testing datasets\n",
        "for mode, dataset in datasets.items():\n",
        "    print(f\"\\n{mode} dataset length: {len(dataset)}\\n\")\n",
        "    print(\"Random sample\")\n",
        "    input, target, input_ids, input_mask, target_ids, target_mask = random.choice(dataset)\n",
        "    print(\"input\\n\", input, end=\"\\n\\n\")\n",
        "    print(\"target\\n\", target, end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train dataset length: 1000\n",
            "\n",
            "Random sample\n",
            "input\n",
            " At present, many people think that English is the world language and it is absolutely an essential skill to communicate with other countries people. Due to this reason , Taiwanese parents do not want their kids to start behind others, thus, many kindergartens started to teach children English.\n",
            "\n",
            "\n",
            "target\n",
            " At present, many people think that English is the world language and it is absolutely an essential skill to communicate with people from other countries . For  this reason,  Taiwanese parents do not want their kids to be  behind others. Therefore , many kindergartens have  started to teach children English.\n",
            "\n",
            "\n",
            "\n",
            "validation dataset length: 300\n",
            "\n",
            "Random sample\n",
            "input\n",
            " No future for public transport?\n",
            "why do use public transport some of us use it to save money for not buying gas or they can't buy a car or if they had problems in their cars or they don't have the mood to drive.\n",
            "Now a days with technology we have different ways to transport like hoverboards,skateboards and maybe it makes No future for public transport \n",
            "Another point is we have our own cars and it's more comfortable, I don't have to wait in line to buy tickets. I don't have to be late for the delays, I can do anything in my own car I can put music I can drink,eat,speak or wherever.\n",
            "I don't have really an opinion I just don't know.we will wait and find out.Tell me your opinions about this subject in comments.\n",
            "\n",
            "target\n",
            " No future for public transport?\n",
            "Why  do we  use public transport? Some  of us use it to save money by  not buying gas or because  they can't buy a car or if they have  problems with  their cars or they are n't in  the mood to drive.\n",
            "Nowadays,  with technology,  we have different ways to get around,  like hoverboards, skateboards,  and maybe it means there is  no  future for public transport.  \n",
            "Another point is that  we have our own cars and it's more comfortable.  I don't have to wait in line to buy tickets. I don't have to be late because of  the delays.  I can do anything in my own car.  I can put music on,  I can drink, eat, speak  or wherever.\n",
            "I don't really have  an opinion,  I just don't know. We  will have to  wait and find out.  Tell me your opinions on  this subject in comments.\n",
            "\n",
            "\n",
            "test dataset length: 130\n",
            "\n",
            "Random sample\n",
            "input\n",
            " \n",
            "Is is commonly-debated that tourism has greatly influenced,not only the aspects of one country,but of the whole world along. \n",
            "Whethere tourism has had a positive or a negative impact over our lifes,it remains quite a dilemma for the ignorants. \n",
            "First of all,tourism is a tool that enables people to travel all around the world.Alongside with its development,the ablity of travalling has easened to such a scale that it is now quite common to commute from one country to another.The existence of multinaionals is tightly connected to the idea of tourism,as well as with the idea of globalisation,since a traveller is not only a citizen of his own country but a global citizen.\n",
            "Secondly,tourism,especially in developed countries,has played an important part in their growing from an economic point of view.There are countries,such as Greece or Bulgaria,in which the econmoy relies merely on tourism.If tourism influences the econmy,it thereby influnces the environment,and if it influences the environment it influences the transport.How?people become more careful at their historcal sites,this way preserving them;Transport is developed both at a small and a large scale:At a small scale,in cities, in a way which will allow citizens and tourists alike to reach important places more efficently.At a large scale,people can now travel in almost any possible way:on land,on sea or air.Through the development of tourism were born cruises and train vacations.\n",
            "\n",
            "\n",
            "target\n",
            " It  is commonly debated  that tourism has greatly influenced  not only the aspects of a  country,  but of the whole world  . \n",
            "Whether  tourism has had a positive or a negative impact on  our lives ,  it remains quite a dilemma for  . \n",
            "First of all,  tourism is a tool that enables people to travel all around the world.  Alongside   its development,  the ability  to  travel  has become easier  to such an  extent  that it is now quite common to commute from one country to another.The existence of multinationals  is tightly connected to the idea of tourism,  as well as to  the idea of globalisation,  since a traveller is not just  a citizen of his own country,  but a global citizen.\n",
            "Secondly,  tourism,  especially in developed countries,  has played an important part in their growth  from an economic point of view.  There are countries,  such as Greece or Bulgaria,  in which the economy  relies completely  on tourism.  If tourism influences the economy ,  it thereby influences  the environment,  and if it influences the environment,  it influences   transport.  How?  People  become more careful at their historical  sites,  thereby  preserving them.  Transport is developed both on  a small and a large scale.  On  a small scale,  in cities, in a way which will allow citizens and tourists alike to reach important places more efficiently .  On  a large scale,  people can now travel in almost any possible way:  on land,  on sea or air.  Through the development of tourism cruises and train vacations were born .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloyt0tIwIiD",
        "colab_type": "text"
      },
      "source": [
        "## Dataloaders\n",
        "\n",
        "Verificação se dataloaders estão funcionando corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoKiQXCvwGrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a0faa592-8682-4bbd-f48a-ba4a5b74c9a1"
      },
      "source": [
        "shuffle = {\"train\": True, \"validation\": False, \"test\": False}\n",
        "debug_dataloaders = {mode: datasets[mode].get_dataloader(batch_size=hparams[\"batch_size\"], \n",
        "                                                         shuffle=shuffle[mode])\n",
        "                     for mode in BEA2019.VALID_MODES}\n",
        "\n",
        "# Testing dataloaders\n",
        "for mode, dataloader in debug_dataloaders.items():\n",
        "    print(\"{} number of batches: {}\".format(mode, len(dataloader)))\n",
        "    batch = next(iter(dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train number of batches: 500\n",
            "validation number of batches: 150\n",
            "test number of batches: 65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGH2rc3lthSB",
        "colab_type": "text"
      },
      "source": [
        "## Lightning Module\n",
        "\n",
        "Aqui a classe principal do PyTorch Lightning é definida.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jg-hZEktbvnr",
        "colab": {}
      },
      "source": [
        "class T5Corrector(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hparams = hparams\n",
        "        self.t5 = T5ForConditionalGeneration.from_pretrained(hparams.model_name,\n",
        "                                                             cache_dir=hparams.base_path)\n",
        "        self.tokenizer = BEA2019.TOKENIZER\n",
        "        self.start_token = BEA2019.TOKENIZER.convert_tokens_to_ids('<extra_id_0>')\n",
        "        self.end_token = BEA2019.TOKENIZER.convert_tokens_to_ids('<extra_id_1>')\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs, targets, input_ids, input_mask, target_ids, target_mask = x\n",
        "\n",
        "        if self.training:\n",
        "            outputs = self.t5(input_ids=input_ids, \n",
        "                              attention_mask=input_mask,\n",
        "                              lm_labels=target_ids)\n",
        "            loss, predicted_scores = outputs[:2]\n",
        "            return loss, predicted_scores, inputs, targets\n",
        "        else:\n",
        "            outputs = self.t5.generate(input_ids=input_ids, \n",
        "                                       attention_mask=input_mask,\n",
        "                                       lm_labels=target_ids,\n",
        "                                       max_length=self.hparams.seq_len)\n",
        "            return outputs, inputs, targets\n",
        "\n",
        "    def training_step(self, batch, targets):\n",
        "        loss, predicted_scores, inputs, targets = self(batch)\n",
        "\n",
        "        return {\"loss\": loss, \"log\": {\"loss\": loss}, \"progress_bar\": hardware_stats()}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs, inputs, targets = self(batch)\n",
        "\n",
        "        predicts = [\n",
        "            html.unescape(\n",
        "                self.tokenizer.decode(output_ids,\n",
        "                                      skip_special_tokens=False,\n",
        "                                      clean_up_tokenization_spaces=False)\n",
        "            )\n",
        "            for output_ids in outputs]\n",
        "\n",
        "        with open(\"orig.txt\", \"w\") as f:\n",
        "            for input in inputs:\n",
        "                input = input.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{input}\\n\")\n",
        "\n",
        "        with open(\"ref.txt\", \"w\") as f:\n",
        "            for target in targets:\n",
        "                target = target.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{target}\\n\")\n",
        "\n",
        "        with open(\"hyp.txt\", \"w\") as f:\n",
        "            for pred in predicts:\n",
        "                pred = pred.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{pred}\\n\")\n",
        "\n",
        "        !errant_parallel -orig orig.txt -cor ref.txt -out ref.m2 > /dev/null\n",
        "        !errant_parallel -orig orig.txt -cor hyp.txt -out hyp.m2 > /dev/null\n",
        "        x = !errant_compare -hyp hyp.m2 -ref ref.m2\n",
        "        df = pd.DataFrame(data=x[2:4])[0].str.split(\"\\t\", expand=True)\n",
        "        new_header = df.iloc[0] #grab the first row for the header\n",
        "        df = df[1:].apply(pd.to_numeric) #take the data less the header row\n",
        "        df.columns = new_header\n",
        "\n",
        "        true_positive = df[\"TP\"][1]\n",
        "        false_positive = df[\"FP\"][1]\n",
        "        false_negative = df[\"FN\"][1]\n",
        "        precision = df[\"Prec\"][1]\n",
        "        recall = df[\"Rec\"][1]\n",
        "        f_score = df[\"F0.5\"][1]\n",
        "\n",
        "        progress_bar = hardware_stats()\n",
        "        progress_bar.update({\"precision\": precision, \"recall\": recall, \"f_score\": f_score})\n",
        "\n",
        "        return {\"true_positive\": true_positive, \"false_positive\": false_positive, \"false_negative\": false_negative,\n",
        "                \"precision\": precision, \"recall\": recall, \"f_score\": f_score,\n",
        "                \"predicts\": predicts, \"inputs\": inputs, \"targets\": targets, \"progress_bar\": progress_bar}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        outputs, inputs, targets = self(batch)\n",
        "\n",
        "        predicts = [\n",
        "            html.unescape(\n",
        "                self.tokenizer.decode(output_ids,\n",
        "                                      skip_special_tokens=False,\n",
        "                                      clean_up_tokenization_spaces=False)\n",
        "            )\n",
        "            for output_ids in outputs]\n",
        "\n",
        "        with open(\"orig.txt\", \"w\") as f:\n",
        "            for input in inputs:\n",
        "                input = input.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{input}\\n\")\n",
        "\n",
        "        with open(\"ref.txt\", \"w\") as f:\n",
        "            for target in targets:\n",
        "                target = target.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{target}\\n\")\n",
        "\n",
        "        with open(\"hyp.txt\", \"w\") as f:\n",
        "            for pred in predicts:\n",
        "                pred = pred.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{pred}\\n\")\n",
        "\n",
        "        !errant_parallel -orig orig.txt -cor ref.txt -out ref.m2 > /dev/null\n",
        "        !errant_parallel -orig orig.txt -cor hyp.txt -out hyp.m2 > /dev/null\n",
        "        x = !errant_compare -hyp hyp.m2 -ref ref.m2\n",
        "        df = pd.DataFrame(data=x[2:4])[0].str.split(\"\\t\", expand=True)\n",
        "        new_header = df.iloc[0] #grab the first row for the header\n",
        "        df = df[1:].apply(pd.to_numeric) #take the data less the header row\n",
        "        df.columns = new_header\n",
        "\n",
        "        true_positive = df[\"TP\"][1]\n",
        "        false_positive = df[\"FP\"][1]\n",
        "        false_negative = df[\"FN\"][1]\n",
        "        precision = df[\"Prec\"][1]\n",
        "        recall = df[\"Rec\"][1]\n",
        "        f_score = df[\"F0.5\"][1]\n",
        "\n",
        "        progress_bar = hardware_stats()\n",
        "        progress_bar.update({\"precision\": precision, \"recall\": recall, \"f_score\": f_score})\n",
        "\n",
        "        return {\"true_positive\": true_positive, \"false_positive\": false_positive, \"false_negative\": false_negative,\n",
        "                \"precision\": precision, \"recall\": recall, \"f_score\": f_score,\n",
        "                \"predicts\": predicts, \"inputs\": inputs, \"targets\": targets, \"progress_bar\": progress_bar}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "\n",
        "        return {\"log\": {\"train_loss\": avg_loss}} \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_precision = sum([x[\"precision\"] for x in outputs]) / len(outputs)\n",
        "        avg_recall = sum([x[\"recall\"] for x in outputs]) / len(outputs)\n",
        "        avg_f_score = sum([x[\"f_score\"] for x in outputs]) / len(outputs)\n",
        "\n",
        "        tensorboard_logs = {\"avg_precision\": avg_precision,\n",
        "                            \"avg_recall\": avg_recall,\n",
        "                            \"avg_f_score\": avg_f_score}\n",
        "\n",
        "        origs = sum([list(x[\"inputs\"]) for x in outputs], [])\n",
        "        trues = sum([list(x[\"targets\"]) for x in outputs], [])\n",
        "        preds = sum([list(x[\"predicts\"]) for x in outputs], [])\n",
        "\n",
        "        n = random.choice(range(len(trues)))\n",
        "        print(f\"\\Input: {origs[n]}\\nTarget: {trues[n]}\\nPrediction: {preds[n]}\\n\")\n",
        "\n",
        "        return {\"avg_precision\": avg_precision, \"avg_recall\": avg_recall, \"avg_f_score\": avg_f_score,\n",
        "                \"log\": tensorboard_logs, \"progress_bar\": tensorboard_logs}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        avg_precision = sum([x[\"precision\"] for x in outputs]) / len(outputs)\n",
        "        avg_recall = sum([x[\"recall\"] for x in outputs]) / len(outputs)\n",
        "        avg_f_score = sum([x[\"f_score\"] for x in outputs]) / len(outputs)\n",
        "\n",
        "        tensorboard_logs = {\"avg_precision\": avg_precision,\n",
        "                            \"avg_recall\": avg_recall,\n",
        "                            \"avg_f_score\": avg_f_score}\n",
        "\n",
        "        origs = sum([list(x[\"inputs\"]) for x in outputs], [])\n",
        "        trues = sum([list(x[\"targets\"]) for x in outputs], [])\n",
        "        preds = sum([list(x[\"predicts\"]) for x in outputs], [])\n",
        "\n",
        "        n = random.choice(range(len(trues)))\n",
        "        print(f\"\\Input: {origs[n]}\\nTarget: {trues[n]}\\nPrediction: {preds[n]}\\n\")\n",
        "        \n",
        "        return {\"avg_precision\": avg_precision, \"avg_recall\": avg_recall, \"avg_f_score\": avg_f_score,\n",
        "                \"log\": tensorboard_logs, \"progress_bar\": tensorboard_logs}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=self.hparams.lr)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        if self.hparams.overfit_pct > 0:\n",
        "            logging.info(\"Disabling train shuffle due to overfit_pct.\")\n",
        "            shuffle = False\n",
        "        else:\n",
        "            shuffle = True\n",
        "        dataset = BEA2019(\"train\", seq_len=self.hparams.seq_len)\n",
        "        return dataset.get_dataloader(batch_size=self.hparams.batch_size, shuffle=shuffle)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        dataset = BEA2019(\"validation\", seq_len=self.hparams.seq_len)\n",
        "        return dataset.get_dataloader(batch_size=self.hparams.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        dataset = BEA2019(\"test\", seq_len=self.hparams.seq_len)\n",
        "        return dataset.get_dataloader(batch_size=self.hparams.batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YbA8e334UM-N"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDAYv5_zURPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "30010878-d0b1-406d-e035-fa454dd7eee3"
      },
      "source": [
        "hparams = {\"name\": experiment_name, \"base_path\": base_path,\n",
        "           \"model_name\": model_name, \"seq_len\": sequence_length,\n",
        "           \"decode_mode\": decode_mode, \"k\": k,\n",
        "           \"lr\": learning_rate, \"batch_size\": batch_size, \"batch_accum\": accumulate_grad_batches,\n",
        "           \"max_epochs\": max_epochs,\n",
        "           \"overfit_pct\": 0, \"debug\": 0,\n",
        "           \"decode_mode\": decode_mode}\n",
        "\n",
        "\n",
        "for key, parameter in hparams.items():\n",
        "    print(\"{}: {}\".format(key, parameter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: fine-tuning\n",
            "base_path: /content/drive/My Drive/PF-Correcao/bea2019st-finetuning\n",
            "model_name: t5-small\n",
            "seq_len: 1000\n",
            "decode_mode: topk\n",
            "k: 10\n",
            "lr: 0.005\n",
            "batch_size: 2\n",
            "batch_accum: 25\n",
            "max_epochs: 10\n",
            "overfit_pct: 0\n",
            "debug: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsxBZdkDzhNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bc867be2-e5a3-4449-d63d-c2db8a239f51"
      },
      "source": [
        "# Instantiate model\n",
        "model = T5Corrector(Namespace(**hparams))\n",
        "\n",
        "# Folder/path management, for logs and checkpoints\n",
        "tensorboard_path = \"logs\"\n",
        "experiment_name = hparams[\"name\"]\n",
        "model_folder = os.path.join(tensorboard_path, experiment_name)\n",
        "os.makedirs(model_folder, exist_ok=True)\n",
        "ckpt_path = os.path.join(model_folder, \"-{epoch}\")\n",
        "\n",
        "# Callback initialization\n",
        "checkpoint_callback = ModelCheckpoint(prefix=experiment_name, \n",
        "                                      filepath=ckpt_path, \n",
        "                                      mode=\"max\")\n",
        "logger = TensorBoardLogger(tensorboard_path, experiment_name)\n",
        "\n",
        "# PL Trainer initialization\n",
        "trainer = Trainer(gpus=1,\n",
        "                  checkpoint_callback=checkpoint_callback, \n",
        "                  early_stop_callback=False,\n",
        "                  logger=logger,\n",
        "                  accumulate_grad_batches=hparams[\"batch_accum\"],\n",
        "                  max_epochs=hparams[\"max_epochs\"], \n",
        "                  fast_dev_run=bool(hparams[\"debug\"]), \n",
        "                  overfit_pct=hparams[\"overfit_pct\"],\n",
        "                  progress_bar_refresh_rate=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcCLkmIvmrx6",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T56srWEzmttv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "66744883-2735-43f2-a622-bade9b46bbbe"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/My Drive/PF-Correcao/bea2019st-finetuning\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 889), started 0:50:39 ago. (Use '!kill 889' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aslaho6VpMSL",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwtRpiSQCKa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5acfb1caa66d414c862e26ab1174c6a2",
            "568f48cf9c26454b8aa214770470aefb",
            "616a530858134a8088283f57f0da41f6",
            "cbebb77c636c4979be37c80958b9ff6a",
            "9a44a9929a9949b2835c64eff46ba0d9",
            "681dbde509e54f41a188c2a229edfa43",
            "6f857124a106438ba038ce5189f7da8f",
            "a9c0754e2378451ebbe89886fda4063f",
            "0506e5bf96e24876bc683efbe28b9c30",
            "dbed467f06cb4e0b85f8c40e2df2bc01",
            "7bcb9864799d435d9f572e8c35666e52",
            "0cc544a887854029944cf30d86bc5187",
            "ffd49a0c613d45658b3034b48b9375ca",
            "d2feab53ddfa40d6a14ef1d329de03c6",
            "b977668d33c64dc39b7156729d576570",
            "9b223f11c77b4501a45343fa5d327f54",
            "fc297e705a0945468a584dfb510d5d5a",
            "492ea405200a447c9dfc31519636a67f",
            "58b622a7fb294b908d3b73f6a9590565",
            "3e1bbc45f55d4663988e689dfee128b6",
            "f5c3494bd7bb46efad13d8e64bf8fcff",
            "105243e6c3a24dc494c1abfed131f57a",
            "e684f676b2e14ed4a24c592f217b0bb4",
            "30a0f593141948359e011df6e69f2db2",
            "859ecf02643c4044b2b663fad56bc924",
            "fabbfc8416e44466b80ab4e74fa2d868",
            "14e111f5f0e44b739bfe0b0bab88358f",
            "b059f53bcb634d22914ad3b6695969da",
            "b1299261b55c47b995696f2599dbee36",
            "997152ef72124eb6948ca7214e6de28d",
            "9256bd0c1db941279fd0514d23b7a605",
            "30f23eb47abe41ae8621a3bb6b018079",
            "e418c84e0f464e1b97c1cbbed06c1258",
            "68e61f84ada94b69acd4bb264c43a9b6",
            "455768c76f57408c9db1d60cdae81c74",
            "60e9f41967864fe491d22716a600d025",
            "815b5457c39b4ed6a304aa8d28c7d46e",
            "19789ffab1d540f6a872a1c6d010de2f",
            "01bf7dc988a847aa94dfd287681ec843",
            "a9d6bdd269db4de9a38030b8f6cb8e7d",
            "7902c80f9dc34eb883501134b2cd3230",
            "d618afbfc1fa46d8a51e705765d9e027",
            "02ff6e69e97f46a2ac25222322356081",
            "510898434dcf401480d0b6b7144ffd9c",
            "fb68ca892f7e43ccb672f35bc10f52ce",
            "cc5988bb8d3c4b4785b42afdae19e56f",
            "f7c58014d6cd46a5922888602e9364fd",
            "967d517f70b8402abe1b95584521a80d"
          ]
        },
        "outputId": "e1fe1855-e490-4910-d79b-2d515e9806f6"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name | Type                       | Params\n",
            "----------------------------------------------------\n",
            "0 | t5   | T5ForConditionalGeneration | 60 M  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5acfb1caa66d414c862e26ab1174c6a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\\Input: Syria has a lot of good restaurants .\n",
            "The Damascus restaurant at the centre of the city is quite a nice place to have a meal.\n",
            "It has all kinds of food even the really fancy ones .\n",
            "You can enjoy having your breakfast there with your family because they have too many types of food .\n",
            "This restaurant also has games for children which they can spend their time playing it .\n",
            "It also includes a huge parking so you can park your own car freely .\n",
            "At Friday they serve special food for those who don't have enough money to pay .\n",
            "It's a very nice restaurant which I prefer the most\n",
            "\n",
            "Target: Syria has a lot of good restaurants. \n",
            "The Damascus restaurant at the centre of the city is quite a nice place to have a meal.\n",
            "It has all kinds of food,  even  really fancy food  .\n",
            "You can enjoy having your breakfast there with your family,  because they have so  many types of food. \n",
            "This restaurant also has games for children,  which they can spend their time playing with  .\n",
            "It also includes a huge car park,  so you can park your own car for free  .\n",
            "On  Friday they serve special food for those who don't have enough money to pay. \n",
            "It's a very nice restaurant which I like  the most. \n",
            "\n",
            "Prediction: <extra_id_0> has a lot of good restaurants . The Damascus restaurant at the centre of the city is quite a nice place to have a meal . It also has games for children which they can spend their time playing it . At Friday they serve special food for those who don't have enough money to pay .\n",
            "\n",
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0506e5bf96e24876bc683efbe28b9c30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc297e705a0945468a584dfb510d5d5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\\Input: I am writing this letter because we have to improve the gym of the school.\n",
            "\n",
            "The gym has many problems that we are gouing to explain :\n",
            "\n",
            "the first problem is that we don´t have enough aparatous for all of the students \n",
            "\n",
            "the second problem is about that same aparatous are not working well because the school didn´t the manteinace long time ago\n",
            "\n",
            "For the first problem in my opinion , the school have to buy some others aparatus because there are not enough for all of the students\n",
            "\n",
            "For the second problem the solution for me is to hire someone to do the maintenance and say to all of the students to take care of the machines of the school\n",
            "\n",
            "I hope my proposal wiil be useful for you\n",
            "\n",
            "I look forward to hearing from you soon\n",
            "\n",
            "Sebastián Ferrari\n",
            "Target: I am writing this letter because we need  to improve the school gym .\n",
            "\n",
            "The gym has many problems that we are going  to describe : \n",
            "\n",
            "The  first problem is that we don´t have enough apparatus  for all of the students.  \n",
            "\n",
            "The  second problem is about that some  apparatus  are not working well because the school hasn't done    maintenance  a  since  long time ago. \n",
            "\n",
            "For the first problem,  in my opinion,  the school should  buy some other  apparatus ,  because there are not enough for all of the students, \n",
            "\n",
            "For the second problem,  the solution,  for me,  is to hire someone to do the maintenance and say to all of the students to take care of the school's machines . \n",
            "\n",
            "I hope my proposal will  be useful to  you. \n",
            "\n",
            "I look forward to hearing from you soon. \n",
            "\n",
            "Sebastián Ferrari\n",
            "Prediction: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of val_loss in validation_epoch_end()?\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "859ecf02643c4044b2b663fad56bc924",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\\Input: Dear Linda, \n",
            "Imy name is Lorenza. My height is 1.65 metres. My hair are browns and my eyes are dark. I will arrive in the Central Station at eleven o'clok and I will wear a read cot and a yellow scarf. See you later. Thank you very much. \n",
            "Lo\n",
            "Target: Dear Linda, \n",
            "My  name is Lorenza. My height is 1.65 metres. My hair is  brown  and my eyes are dark. I will arrive at  the Central Station at eleven o'clock  and I will wear a read coat  and a yellow scarf. See you later. Thank you very much. \n",
            "Lo\n",
            "Prediction: Imy name is Lorenza. My height is 1.65 metres. My hair are browns and my eyes are dark. I will arrive at the Central Station at eleven o'clok and I will wear a read cot and a yellow scarf. See you later. Thank you very much. Lorenza. Thank you very much. Lorenza. My height is 1.65 metres. My hair are browns and my eyes are dark. I will arrive at the Central Station at eleven o'clok and I will wear a read cot and a red scarf. See you later. Thank you very much.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e418c84e0f464e1b97c1cbbed06c1258",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\\Input: How we treat the earth has a direct impact on ourselves. Today,because of our progress of industry, we produced so many environmental problems that hadn't appeared before. For examples, lack of purity water, shortage of electricity, climate change, natural source depletion,and etc. The problems weren't so significant that we overlooked them, but now they become  serious threats that we can't ignore. How can we solve these problems?  Just change your daily habits. \n",
            "\n",
            "Target: How we treat the earth has a direct impact on ourselves. Today, because  of the  progress of industry, we have caused  so many environmental problems that did n't arise  before. For example , lack of clean  water, shortage of electricity, climate change, natural resource  depletion,  etc. The problems weren't very  significant so  we overlooked them, but now they have  become  serious threats that we can't ignore. How can we solve these problems?  Just change your daily habits. \n",
            "\n",
            "Prediction: Nowadays, because of our progress in industry, we produced so many environmental problems that hadn't appeared before. For example, lack of purity water, shortage of electricity, a shortage of electricity, the shortage of electricity, the shortage of electricity, climate change, natural sources of pollution, and etc. The problems weren't so significant that we overlooked them, but now they become serious threats that we can't ignore. How can we solve these problems? Just change your daily habits.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7902c80f9dc34eb883501134b2cd3230",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\\Input: Hello Julia,\n",
            "How are you?\n",
            "What did you do yestreday?\n",
            "I went to the cinema to watch a comedy with my friends yesterday, but I didn't like it because it was so boring.\n",
            "I prefer another kind of films than comedy, but yesterday there weren't any good film at the cinema.\n",
            "what kind of films do you like?\n",
            "I like thriller and the action films because they have never been boring.\n",
            "Do you prefer to watch films at home or go to the cinema?\n",
            "I prefer to watch films at the cinema because there aren't any distractions or noises and the quality of films are better.\n",
            "\n",
            "See you soon.\n",
            "Erica \n",
            "Target: Hello Julia,\n",
            "How are you?\n",
            "What did you do yesterday ?\n",
            "I went to the cinema to watch a comedy with my friends yesterday, but I didn't like it because it was so boring.\n",
            "I prefer other  kinds  of films than comedy, but yesterday there weren't any good films  at the cinema.\n",
            "What  kind of films do you like?\n",
            "I like thrillers  and the action films because they are never  boring.\n",
            "Do you prefer watching  films at home or going  to the cinema?\n",
            "I prefer to watch films at the cinema because there aren't any distractions or noises and the quality of films is  better.\n",
            "\n",
            "See you soon.\n",
            "Erica \n",
            "Prediction: Hello Julia, How are you? What did you do? Yestreday? I went to the cinema to watch a comedy with my friends yesterday, but I didn't like it because it was so boring. I prefer another kind of films than comedy, but yesterday there weren't any good films at cinema. What kind of films do you like? I like thriller and action films because they have never been boring. Do you prefer to watch films at home or go to the cinema? I prefer to watch films at the cinema because there aren't any distractions or noises and the quality of films are better. See you soon. Erica\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ercKNf1x_WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TYZSh-UvOJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}