{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Correcao_T5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fberanizo/spelling-correction/blob/master/Correcao_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up4u8rMkQSG",
        "colab_type": "text"
      },
      "source": [
        "# Detecção e correção de erro ortográfico com modelo T5\n",
        "\n",
        "**Nome: Fabio Beranizo Lopes**<br>\n",
        "**Nome: Luiz Pita Almeida**\n",
        "\n",
        "Usaremos o modelo T5 pré-treinado e o dataset Paracrawl Inglês-Português. <br>\n",
        "Truncamos para strings de tamanho 100 para deixar os testes mais rápidos.\n",
        "\n",
        "Passos:\n",
        "\n",
        "1. Pressupõe que as frases to Paracrawl estão corretas.<br>\n",
        "2. Aplica-se todas as técnicas para corromper amostras:\n",
        "   - Drop\n",
        "   - Swap\n",
        "   - Add\n",
        "   - Key\n",
        "3. Treina-se o modelo T5 com as frases corrompidas como entrada e frase corrigida (original) como saída.\n",
        "\n",
        "**Obs: os notebooks contém excertos de códigos dos colegas de turma.**<br>\n",
        "**Obrigado Diedre, Leard e Gabriela.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpELBvNmku5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e72b2f2e-eb44-4efd-8b99-9a608d16bf80"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# don't even start if it's not a P100 GPU\n",
        "# if torch.cuda.get_device_name(0) != \"Tesla P100-PCIE-16GB\":\n",
        "#     import os\n",
        "#     os.kill(os.getpid(), 9)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgW-boJLU0wU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Configurações gerais\n",
        "experiment_name = \"adversarial-misspellings\"  #@param {type:\"string\"}\n",
        "model_name = \"t5-small\"  #@param [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3B\", \"t5-11B\"] {type:\"string\"}\n",
        "batch_size = 100  #@param {type:\"integer\"}\n",
        "accumulate_grad_batches = 1  #@param {type:\"integer\"}\n",
        "sequence_length = 100  #@param {type:\"integer\"}\n",
        "learning_rate = 5e-3  #@param {type:\"number\"}\n",
        "decode_mode = \"topk\"  #@param [\"greedy\", \"nucleus\", \"topk\", \"beam\"] {type:\"string\"}\n",
        "k = 10  #@param {type:\"integer\"}\n",
        "max_epochs = 1  #@param {type:\"integer\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U0dTSB-mnGN",
        "colab_type": "text"
      },
      "source": [
        "## Instala dependências\n",
        "\n",
        "- PyTorch Lightning\n",
        "- Hugginface Transformers\n",
        "- ERRANT (ERRor ANnotation Toolkit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOXZxjWRkLMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ae85543-632d-4c00-a8f0-fd7a65620e70"
      },
      "source": [
        "!git clone --quiet https://github.com/danishpruthi/Adversarial-Misspellings.git\n",
        "\n",
        "try:\n",
        "    import pytorch_lightning\n",
        "    import transformers\n",
        "except (ImportError, ModuleNotFoundError) as e:\n",
        "    pass\n",
        "    # can't import modules, then install\n",
        "    # !pip install --quiet pytorch-lightning\n",
        "    # !pip install --quiet transformers\n",
        "    # !pip install --quiet errant==2.2.0\n",
        "    # !pip install pyxDamerauLevenshtein\n",
        "    # !python -m spacy download en\n",
        "    # # kill kernel (necessary for tqdm)\n",
        "    # import os\n",
        "    # os.kill(os.getpid(), 9)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Adversarial-Misspellings' already exists and is not an empty directory.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob7qL6kUVjbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2cd94262-b985-4a22-8daa-2899ba79e75b"
      },
      "source": [
        "# Importar todos os pacotes de uma só vez para evitar duplicados ao longo do notebook.\n",
        "import datetime\n",
        "import errant\n",
        "import gzip\n",
        "import json\n",
        "import numpy as np\n",
        "import nvidia_smi\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import psutil\n",
        "import pytorch_lightning as pl\n",
        "import random\n",
        "import spacy\n",
        "import sys\n",
        "import tarfile\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from argparse import Namespace\n",
        "from collections import deque\n",
        "# from google.colab import drive\n",
        "from itertools import cycle\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "from transformers import T5ForConditionalGeneration\n",
        "from transformers import T5Tokenizer\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "\n",
        "# Leard decoding solution\n",
        "import html\n",
        "import unicodedata\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "annotator = errant.load(\"en\", nlp)\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "sys.path.insert(0, \"/content/Adversarial-Misspellings\")\n",
        "import attacks\n",
        "\n",
        "nvidia_smi.nvmlInit()\n",
        "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
        "\n",
        "def hardware_stats():\n",
        "    \"\"\"\n",
        "    Returns a dict containing some hardware related stats\n",
        "    \"\"\"\n",
        "    res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
        "    return {\"cpu\": f\"{str(psutil.cpu_percent())}%\",\n",
        "            \"mem\": f\"{str(psutil.virtual_memory().percent)}%\",\n",
        "            \"gpu\": f\"{str(res.gpu)}%\",\n",
        "            \"gpu_mem\": f\"{str(res.memory)}%\"}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/fabiol/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8H4Rfwm2gE",
        "colab_type": "text"
      },
      "source": [
        "## Define random seeds\n",
        "\n",
        "Importante: Fix seeds so we can replicate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJlZDb1VY29r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "torch.random.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETfkvMGl4JA1",
        "colab_type": "text"
      },
      "source": [
        "## Mapeia Google Drive\n",
        "\n",
        "Iremos salvar os checkpoints (pesos do modelo) no google drive, para que possamos continuar o treino de onde paramos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hvGjweSKfbA2",
        "colab": {}
      },
      "source": [
        "# drive.mount(\"/content/drive\")\n",
        "# base_path = \"/content/drive/My Drive/PF-Correcao/paracrawl-t5\"\n",
        "base_path = \"/content/paracrawl-t5\"\n",
        "os.environ[\"BASE_PATH\"] = base_path"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TgUkD55Dkam2"
      },
      "source": [
        "## Classe Dataset\n",
        "Gerenciamento dos dados, e um pequeno teste.\n",
        "No getitem é aplicada a correção de codificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R2GaMtgRkaze",
        "colab": {}
      },
      "source": [
        "hparams = {\"model_name\": model_name, \"seq_len\": sequence_length, \"batch_size\": batch_size}\n",
        "class ParaCrawl(Dataset):\n",
        "    \"\"\"\n",
        "    Loads data from preprocessed file and manages them.\n",
        "    \"\"\"\n",
        "    VALID_MODES = [\"train\", \"validation\", \"test\"]\n",
        "    TOKENIZER = T5Tokenizer.from_pretrained(hparams[\"model_name\"],\n",
        "                                            cache_dir=base_path)\n",
        "    def __init__(self, mode: str, seq_len: int):\n",
        "        \"\"\"\n",
        "        mode: One of train, validation or test \n",
        "        seq_len: limit to returned encoded tokens\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert mode in ParaCrawl.VALID_MODES\n",
        "\n",
        "        self.mode = mode\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        file_name = os.path.join(base_path, f\"{mode}.pkl\")\n",
        "        if not os.path.isfile(file_name):\n",
        "            print(\"Pre-processed files not found, preparing data.\")\n",
        "            self.prepare_data()\n",
        "        \n",
        "        with open(file_name, \"rb\") as preprocessed_file:\n",
        "            self.data = joblib.load(preprocessed_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i: int):\n",
        "        \"\"\"\n",
        "        Unpacks line from data.\n",
        "\n",
        "        returns: input (corrputed), target (corrected)\n",
        "        \"\"\"\n",
        "        input, target = self.data[i]\n",
        "\n",
        "        input_normalized = unicodedata.normalize(\"NFD\", input).\\\n",
        "            encode(\"latin-1\", \"xmlcharrefreplace\").\\\n",
        "            decode(\"latin-1\")\n",
        "\n",
        "        input_encoded = ParaCrawl.TOKENIZER.encode_plus(\n",
        "            f\"{input_normalized} {ParaCrawl.TOKENIZER.eos_token}\",\n",
        "            max_length=self.seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = input_encoded[\"input_ids\"].squeeze()\n",
        "        input_mask = input_encoded[\"attention_mask\"].squeeze()\n",
        "\n",
        "        target_normalized = unicodedata.normalize(\"NFD\", target).\\\n",
        "            encode(\"latin-1\", \"xmlcharrefreplace\").\\\n",
        "            decode(\"latin-1\")\n",
        "\n",
        "        target_encoded = ParaCrawl.TOKENIZER.encode_plus(\n",
        "            f\"{target_normalized} {ParaCrawl.TOKENIZER.eos_token}\",\n",
        "            max_length=self.seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors=\"pt\")\n",
        "\n",
        "        target_ids = target_encoded[\"input_ids\"].squeeze()\n",
        "        target_mask = target_encoded[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return input, target, input_ids, input_mask, target_ids, target_mask\n",
        "\n",
        "    def get_dataloader(self, batch_size: int, shuffle: bool):\n",
        "        return DataLoader(self, batch_size=batch_size, shuffle=shuffle, \n",
        "                          num_workers=4)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_text_pairs(path):\n",
        "        \"\"\"\n",
        "        Load pairs from original files, selects pt, then corrupts the samples.\n",
        "        \"\"\"\n",
        "        text_pairs = []\n",
        "        for line in tqdm_notebook(gzip.open(path, mode=\"rt\")):\n",
        "            text_pt = line.strip().split(\"\\t\")[1]\n",
        "            text_pt = text_pt[:hparams[\"seq_len\"]].rsplit(\" \", 1)[0]\n",
        "            try:\n",
        "                attack_list = deque(attacks.all_one_attack(text_pt, include_ends=True))\n",
        "                text_corrupt = list(map(lambda a: a[1], random.sample(attack_list, k=10)))\n",
        "                text_pairs.extend(list(zip(text_corrupt, cycle([text_pt]))))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        return text_pairs\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_data(train_size=9997000, val_size=3000):\n",
        "        \"\"\"\n",
        "        Performs everything needed to get the data ready.\n",
        "        Addition of Eos token and encoding is performed in runtime.\n",
        "        \"\"\"\n",
        "        if not os.path.isfile(\"paracrawl_enpt_train.tsv.gz\"):    \n",
        "            !wget -nc https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2020s1/paracrawl_enpt_train.tsv.gz -P \"$BASE_PATH\"\n",
        "            !wget -nc https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2020s1/paracrawl_enpt_test.tsv.gz -P \"$BASE_PATH\"\n",
        "\n",
        "        data = {}\n",
        "        test_data = ParaCrawl.load_text_pairs(os.path.join(base_path, \"paracrawl_enpt_test.tsv.gz\"))\n",
        "        train_val_data = ParaCrawl.load_text_pairs(os.path.join(base_path, \"paracrawl_enpt_train.tsv.gz\"))\n",
        "\n",
        "        random.shuffle(train_val_data)\n",
        "\n",
        "        train_data = train_val_data[:train_size]\n",
        "        val_data = train_val_data[train_size:train_size + val_size]\n",
        "\n",
        "        for mode, data in zip(ParaCrawl.VALID_MODES, [train_data, val_data, test_data]):\n",
        "            file_name = os.path.join(base_path, f\"{mode}.pkl\")\n",
        "            with open(file_name, \"wb\") as pkl_file:\n",
        "                joblib.dump(data, pkl_file)\n",
        "            print(f\"Pre-processed data saved as {file_name}.\")\n",
        "\n",
        "\n",
        "datasets = {m: ParaCrawl(mode=m, seq_len=hparams[\"seq_len\"]) for m in ParaCrawl.VALID_MODES}\n",
        "\n",
        "# Testing datasets\n",
        "for mode, dataset in datasets.items():\n",
        "    print(f\"\\n{mode} dataset length: {len(dataset)}\\n\")\n",
        "    print(\"Random sample\")\n",
        "    input, target, input_ids, input_mask, target_ids, target_mask = random.choice(dataset)\n",
        "    print(\"input\\n\", input, end=\"\\n\\n\")\n",
        "    print(\"target\\n\", target, end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloyt0tIwIiD",
        "colab_type": "text"
      },
      "source": [
        "## Dataloaders\n",
        "\n",
        "Verificação se dataloaders estão funcionando corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoKiQXCvwGrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle = {\"train\": True, \"validation\": False, \"test\": False}\n",
        "debug_dataloaders = {mode: datasets[mode].get_dataloader(batch_size=hparams[\"batch_size\"], \n",
        "                                                         shuffle=shuffle[mode])\n",
        "                     for mode in ParaCrawl.VALID_MODES}\n",
        "\n",
        "# Testing dataloaders\n",
        "for mode, dataloader in debug_dataloaders.items():\n",
        "    print(\"{} number of batches: {}\".format(mode, len(dataloader)))\n",
        "    batch = next(iter(dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGH2rc3lthSB",
        "colab_type": "text"
      },
      "source": [
        "## Lightning Module\n",
        "\n",
        "Aqui a classe principal do PyTorch Lightning é definida.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jg-hZEktbvnr",
        "colab": {}
      },
      "source": [
        "class T5Corrector(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hparams = hparams\n",
        "        self.t5 = T5ForConditionalGeneration.from_pretrained(hparams.model_name,\n",
        "                                                             cache_dir=hparams.base_path)\n",
        "        self.tokenizer = ParaCrawl.TOKENIZER\n",
        "        self.start_token = ParaCrawl.TOKENIZER.convert_tokens_to_ids(\"<extra_id_0>\")\n",
        "        self.end_token = ParaCrawl.TOKENIZER.convert_tokens_to_ids(\"<extra_id_1>\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        inputs, targets, input_ids, input_mask, target_ids, target_mask = x\n",
        "\n",
        "        if self.training:\n",
        "            outputs = self.t5(input_ids=input_ids, \n",
        "                              attention_mask=input_mask,\n",
        "                              lm_labels=target_ids)\n",
        "            loss, predicted_scores = outputs[:2]\n",
        "            return loss, predicted_scores, inputs, targets\n",
        "        else:\n",
        "            outputs = self.t5.generate(input_ids=input_ids, \n",
        "                                       attention_mask=input_mask,\n",
        "                                       lm_labels=target_ids,\n",
        "                                       max_length=self.hparams.seq_len)\n",
        "            return outputs, inputs, targets\n",
        "\n",
        "    def training_step(self, batch, targets):\n",
        "        loss, predicted_scores, inputs, targets = self(batch)\n",
        "\n",
        "        return {\"loss\": loss, \"log\": {\"loss\": loss}, \"progress_bar\": hardware_stats()}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs, inputs, targets = self(batch)\n",
        "\n",
        "        predicts = [\n",
        "            html.unescape(\n",
        "                self.tokenizer.decode(output_ids,\n",
        "                                      skip_special_tokens=False,\n",
        "                                      clean_up_tokenization_spaces=False)\n",
        "            )\n",
        "            for output_ids in outputs]\n",
        "\n",
        "        with open(\"orig.txt\", \"w\") as f:\n",
        "            for input in inputs:\n",
        "                input = input.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{input}\\n\")\n",
        "\n",
        "        with open(\"ref.txt\", \"w\") as f:\n",
        "            for target in targets:\n",
        "                target = target.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{target}\\n\")\n",
        "\n",
        "        with open(\"hyp.txt\", \"w\") as f:\n",
        "            for pred in predicts:\n",
        "                pred = pred.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{pred}\\n\")\n",
        "\n",
        "        !errant_parallel -orig orig.txt -cor ref.txt -out ref.m2 > /dev/null\n",
        "        !errant_parallel -orig orig.txt -cor hyp.txt -out hyp.m2 > /dev/null\n",
        "        x = !errant_compare -hyp hyp.m2 -ref ref.m2\n",
        "        df = pd.DataFrame(data=x[2:4])[0].str.split(\"\\t\", expand=True)\n",
        "        new_header = df.iloc[0] #grab the first row for the header\n",
        "        df = df[1:].apply(pd.to_numeric) #take the data less the header row\n",
        "        df.columns = new_header\n",
        "\n",
        "        true_positive = df[\"TP\"][1]\n",
        "        false_positive = df[\"FP\"][1]\n",
        "        false_negative = df[\"FN\"][1]\n",
        "        precision = df[\"Prec\"][1]\n",
        "        recall = df[\"Rec\"][1]\n",
        "        f_score = df[\"F0.5\"][1]\n",
        "\n",
        "        progress_bar = hardware_stats()\n",
        "        progress_bar.update({\"precision\": precision, \"recall\": recall, \"f_score\": f_score})\n",
        "\n",
        "        return {\"true_positive\": true_positive, \"false_positive\": false_positive, \"false_negative\": false_negative,\n",
        "                \"precision\": precision, \"recall\": recall, \"f_score\": f_score,\n",
        "                \"predicts\": predicts, \"inputs\": inputs, \"targets\": targets, \"progress_bar\": progress_bar}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        outputs, inputs, targets = self(batch)\n",
        "\n",
        "        predicts = [\n",
        "            html.unescape(\n",
        "                self.tokenizer.decode(output_ids,\n",
        "                                      skip_special_tokens=False,\n",
        "                                      clean_up_tokenization_spaces=False)\n",
        "            )\n",
        "            for output_ids in outputs]\n",
        "\n",
        "        with open(\"orig.txt\", \"w\") as f:\n",
        "            for input in inputs:\n",
        "                input = input.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{input}\\n\")\n",
        "\n",
        "        with open(\"ref.txt\", \"w\") as f:\n",
        "            for target in targets:\n",
        "                target = target.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{target}\\n\")\n",
        "\n",
        "        with open(\"hyp.txt\", \"w\") as f:\n",
        "            for pred in predicts:\n",
        "                pred = pred.replace(\"\\n\", \"\")\n",
        "                f.write(f\"{pred}\\n\")\n",
        "\n",
        "        !errant_parallel -orig orig.txt -cor ref.txt -out ref.m2 > /dev/null\n",
        "        !errant_parallel -orig orig.txt -cor hyp.txt -out hyp.m2 > /dev/null\n",
        "        x = !errant_compare -hyp hyp.m2 -ref ref.m2\n",
        "        df = pd.DataFrame(data=x[2:4])[0].str.split(\"\\t\", expand=True)\n",
        "        new_header = df.iloc[0] #grab the first row for the header\n",
        "        df = df[1:].apply(pd.to_numeric) #take the data less the header row\n",
        "        df.columns = new_header\n",
        "\n",
        "        true_positive = df[\"TP\"][1]\n",
        "        false_positive = df[\"FP\"][1]\n",
        "        false_negative = df[\"FN\"][1]\n",
        "        precision = df[\"Prec\"][1]\n",
        "        recall = df[\"Rec\"][1]\n",
        "        f_score = df[\"F0.5\"][1]\n",
        "\n",
        "        progress_bar = hardware_stats()\n",
        "        progress_bar.update({\"precision\": precision, \"recall\": recall, \"f_score\": f_score})\n",
        "\n",
        "        return {\"true_positive\": true_positive, \"false_positive\": false_positive, \"false_negative\": false_negative,\n",
        "                \"precision\": precision, \"recall\": recall, \"f_score\": f_score,\n",
        "                \"predicts\": predicts, \"inputs\": inputs, \"targets\": targets, \"progress_bar\": progress_bar}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "\n",
        "        return {\"log\": {\"train_loss\": avg_loss}} \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_precision = sum([x[\"precision\"] for x in outputs]) / len(outputs)\n",
        "        avg_recall = sum([x[\"recall\"] for x in outputs]) / len(outputs)\n",
        "        avg_f_score = sum([x[\"f_score\"] for x in outputs]) / len(outputs)\n",
        "\n",
        "        tensorboard_logs = {\"val_loss\": avg_f_score,\n",
        "                            \"avg_precision\": avg_precision,\n",
        "                            \"avg_recall\": avg_recall,\n",
        "                            \"avg_f_score\": avg_f_score}\n",
        "\n",
        "        origs = sum([list(x[\"inputs\"]) for x in outputs], [])\n",
        "        trues = sum([list(x[\"targets\"]) for x in outputs], [])\n",
        "        preds = sum([list(x[\"predicts\"]) for x in outputs], [])\n",
        "\n",
        "        n = random.choice(range(len(trues)))\n",
        "        print(f\"\\Input: {origs[n]}\\nTarget: {trues[n]}\\nPrediction: {preds[n]}\\n\")\n",
        "\n",
        "        return {\"val_loss\": avg_f_score, \"avg_precision\": avg_precision, \"avg_recall\": avg_recall, \"avg_f_score\": avg_f_score,\n",
        "                \"log\": tensorboard_logs, \"progress_bar\": tensorboard_logs}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        avg_precision = sum([x[\"precision\"] for x in outputs]) / len(outputs)\n",
        "        avg_recall = sum([x[\"recall\"] for x in outputs]) / len(outputs)\n",
        "        avg_f_score = sum([x[\"f_score\"] for x in outputs]) / len(outputs)\n",
        "\n",
        "        tensorboard_logs = {\"avg_precision\": avg_precision,\n",
        "                            \"avg_recall\": avg_recall,\n",
        "                            \"avg_f_score\": avg_f_score}\n",
        "\n",
        "        origs = sum([list(x[\"inputs\"]) for x in outputs], [])\n",
        "        trues = sum([list(x[\"targets\"]) for x in outputs], [])\n",
        "        preds = sum([list(x[\"predicts\"]) for x in outputs], [])\n",
        "\n",
        "        n = random.choice(range(len(trues)))\n",
        "        print(f\"\\Input: {origs[n]}\\nTarget: {trues[n]}\\nPrediction: {preds[n]}\\n\")\n",
        "        \n",
        "        return {\"avg_precision\": avg_precision, \"avg_recall\": avg_recall, \"avg_f_score\": avg_f_score,\n",
        "                \"log\": tensorboard_logs, \"progress_bar\": tensorboard_logs}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=self.hparams.lr)    \n",
        "\n",
        "    def train_dataloader(self):\n",
        "        if self.hparams.overfit_pct > 0:\n",
        "            logging.info(\"Disabling train shuffle due to overfit_pct.\")\n",
        "            shuffle = False\n",
        "        else:\n",
        "            shuffle = True\n",
        "        dataset = ParaCrawl(\"train\", seq_len=self.hparams.seq_len)\n",
        "        return dataset.get_dataloader(batch_size=self.hparams.batch_size, shuffle=shuffle)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        dataset = ParaCrawl(\"validation\", seq_len=self.hparams.seq_len)\n",
        "        return dataset.get_dataloader(batch_size=self.hparams.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        dataset = ParaCraw(\"test\", seq_len=self.hparams.seq_len)\n",
        "        return dataset.get_dataloader(batch_size=self.hparams.batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YbA8e334UM-N"
      },
      "source": [
        "## Preparação e Treino\n",
        "Define-se hiperparâmetros para um treinamento de melhora, agora com decodificação corrigida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDAYv5_zURPc",
        "colab": {}
      },
      "source": [
        "hparams = {\"name\": experiment_name, \"base_path\": base_path,\n",
        "           \"model_name\": model_name, \"seq_len\": sequence_length,\n",
        "           \"decode_mode\": decode_mode, \"k\": k,\n",
        "           \"lr\": learning_rate, \"batch_size\": batch_size, \"batch_accum\": accumulate_grad_batches,\n",
        "           \"max_epochs\": max_epochs,\n",
        "           \"overfit_pct\": 0, \"debug\": 0,\n",
        "           \"decode_mode\": decode_mode}\n",
        "\n",
        "\n",
        "for key, parameter in hparams.items():\n",
        "    print(\"{}: {}\".format(key, parameter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsxBZdkDzhNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate model\n",
        "model = T5Corrector(Namespace(**hparams))\n",
        "\n",
        "# Folder/path management, for logs and checkpoints\n",
        "tensorboard_path = os.path.join(base_path, \"logs\")\n",
        "experiment_name = hparams[\"name\"]\n",
        "model_folder = os.path.join(tensorboard_path, experiment_name)\n",
        "os.makedirs(model_folder, exist_ok=True)\n",
        "ckpt_path = os.path.join(model_folder, \"-{epoch}\")\n",
        "\n",
        "# Callback initialization\n",
        "checkpoint_callback = ModelCheckpoint(prefix=experiment_name, \n",
        "                                      filepath=ckpt_path, \n",
        "                                      mode=\"max\",\n",
        "                                      verbose=True)\n",
        "logger = TensorBoardLogger(tensorboard_path, experiment_name, version=0)\n",
        "\n",
        "# PL Trainer initialization\n",
        "trainer = Trainer(gpus=1,\n",
        "                  checkpoint_callback=checkpoint_callback, \n",
        "                  early_stop_callback=False,\n",
        "                  logger=logger,\n",
        "                  accumulate_grad_batches=hparams[\"batch_accum\"],\n",
        "                  max_epochs=hparams[\"max_epochs\"], \n",
        "                  fast_dev_run=bool(hparams[\"debug\"]), \n",
        "                  overfit_pct=hparams[\"overfit_pct\"],\n",
        "                  progress_bar_refresh_rate=10,\n",
        "                  val_check_interval=0.1, # check validation set 10 times during a training epoch\n",
        "                  profiler=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcCLkmIvmrx6",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T56srWEzmttv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/paracrawl-t5\"\n",
        "# %tensorboard --logdir \"/content/drive/My Drive/PF-Correcao/paracrawl-t5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aslaho6VpMSL",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "suyIF3ifpqpx",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqdHUPY2pO7i",
        "colab_type": "text"
      },
      "source": [
        "## Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efVSbZD1-chp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GIqGCy1APFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}